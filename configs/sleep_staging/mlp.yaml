project: sleep-staging
_base:
  - configs/sleep_staging/base.yaml
data:
  common:
    batch_size: 16
    num_workers: 16
task:
  model:
    _name: models.sleep_staging.SleepStagingNetMLP
    hidden_size: 512
    num_hidden_layers: 6
    num_attention_heads: 8
    intermediate_size: 2048
  optimizer:
    _name: torch.optim.Adam
    lr: 0.0001

PATIENCE: 10
